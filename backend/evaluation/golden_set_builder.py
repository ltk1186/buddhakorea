"""
Golden Set Builder for Buddhist RAG Evaluation
Generates high-quality Q&A pairs using Gemini 2.0 Flash
"""

import json
import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from loguru import logger
import vertexai
from vertexai.generative_models import GenerativeModel, GenerationConfig

# Configure logging
logger.remove()
logger.add(sys.stdout, level="INFO")

# GCP Configuration
GCP_PROJECT_ID = os.getenv("GCP_PROJECT_ID", "gen-lang-client-0324154376")
GCP_LOCATION = os.getenv("GCP_LOCATION", "us-central1")
MODEL_NAME = "gemini-2.0-flash-exp"

# Initialize Vertex AI
vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
model = GenerativeModel(MODEL_NAME)

generation_config = GenerationConfig(
    temperature=0.7,  # Higher for diverse questions
    max_output_tokens=2048,
    top_p=0.9,
)


class GoldenSetBuilder:
    """Builds evaluation golden set from CBETA corpus"""

    def __init__(self, source_summaries_path: str, output_path: str):
        self.source_summaries_path = source_summaries_path
        self.output_path = output_path
        self.golden_set = self._load_golden_set()

    def _load_golden_set(self) -> Dict[str, Any]:
        """Load existing golden set or create new one"""
        if os.path.exists(self.output_path):
            with open(self.output_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {
                "metadata": {
                    "version": "1.0",
                    "created_at": time.strftime('%Y-%m-%d'),
                    "description": "Golden evaluation set for Buddhist RAG system",
                    "total_questions": 0,
                    "categories": {
                        "factual": "Factual questions about specific Buddhist concepts",
                        "interpretive": "Questions requiring interpretation of teachings",
                        "comparative": "Questions comparing different sutras or concepts",
                        "practical": "Questions about Buddhist practice"
                    }
                },
                "questions": []
            }

    def _load_source_summaries(self) -> Dict[str, Any]:
        """Load source summaries with Korean translations"""
        with open(self.source_summaries_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def generate_questions_for_sutra(
        self,
        sutra_id: str,
        title_ko: str,
        brief_summary: str,
        detailed_summary: str,
        key_themes: List[str],
        tradition: str,
        num_questions: int = 5
    ) -> List[Dict[str, Any]]:
        """Generate diverse evaluation questions for a specific sutra"""

        prompt = f"""ë‹¹ì‹ ì€ ë¶ˆêµ êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ë‹¤ìŒ ë¬¸í—Œì— ëŒ€í•œ í‰ê°€ìš© ì§ˆë¬¸-ë‹µë³€ ìŒì„ ìƒì„±í•˜ì„¸ìš”.

**ë¬¸í—Œ ì •ë³´:**
- ID: {sutra_id}
- ì œëª©: {title_ko}
- ê°„ëžµ ìš”ì•½: {brief_summary}
- ìƒì„¸ ìš”ì•½: {detailed_summary}
- í•µì‹¬ ì£¼ì œ: {', '.join(key_themes)}
- ì „í†µ: {tradition}

**ìž‘ì„± ìš”êµ¬ì‚¬í•­:**
{num_questions}ê°œì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì„ ìƒì„±í•˜ì„¸ìš”. ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¥¼ ê³¨ê³ ë£¨ í¬í•¨:

1. **factual** (ì‚¬ì‹¤ ì§ˆë¬¸): ë¬¸í—Œì˜ êµ¬ì²´ì  ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸
   - ì˜ˆ: "ì´ ë¬¸í—Œì—ì„œ ì„¤ëª…í•˜ëŠ” ì‚¬ì„±ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?"

2. **interpretive** (í•´ì„ ì§ˆë¬¸): ê°€ë¥´ì¹¨ì˜ ì˜ë¯¸ë¥¼ í•´ì„í•˜ëŠ” ì§ˆë¬¸
   - ì˜ˆ: "ì´ ë¬¸í—Œì—ì„œ ê³µ(ç©º) ì‚¬ìƒì€ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§€ë‚˜ìš”?"

3. **practical** (ì‹¤ì²œ ì§ˆë¬¸): ìˆ˜í–‰ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸
   - ì˜ˆ: "ì´ ë¬¸í—Œì— ë”°ë¥´ë©´ ì–´ë–»ê²Œ ëª…ìƒì„ ì‹¤ì²œí•´ì•¼ í•˜ë‚˜ìš”?"

**ì§ˆë¬¸ ìž‘ì„± ì§€ì¹¨:**
- ìžì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ìž‘ì„±
- ì´ˆë³´ìžë„ ì´í•´í•  ìˆ˜ ìžˆëŠ” ëª…í™•í•œ ì–¸ì–´ ì‚¬ìš©
- ë¬¸í—Œì˜ êµ¬ì²´ì  ë‚´ìš©ì„ ì°¸ì¡°í•  ìˆ˜ ìžˆëŠ” ì§ˆë¬¸
- ë„ˆë¬´ ì¼ë°˜ì ì´ê±°ë‚˜ ëª¨í˜¸í•˜ì§€ ì•Šê²Œ

**ë‹µë³€ ìž‘ì„± ì§€ì¹¨:**
- ë¬¸í—Œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ìž‘ì„±
- 200-400ìž ë¶„ëŸ‰
- í•µì‹¬ ê°œë…ì„ ëª…í™•ížˆ ì„¤ëª…
- í•„ìš”ì‹œ ì˜ˆì‹œ í¬í•¨

**ì¶œë ¥ í˜•ì‹ (JSON):**
```json
[
  {{
    "question": "ì§ˆë¬¸ ë‚´ìš©",
    "answer": "ë‹µë³€ ë‚´ìš© (200-400ìž)",
    "category": "factual|interpretive|practical",
    "sutra_id": "{sutra_id}",
    "difficulty": "easy|medium|hard",
    "key_concepts": ["ê°œë…1", "ê°œë…2"]
  }},
  ...
]
```

ë¶ˆêµí•™ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ ê³ í’ˆì§ˆ Q&Aë¥¼ ìƒì„±í•˜ì„¸ìš”.
"""

        try:
            response = model.generate_content(
                prompt,
                generation_config=generation_config
            )

            # Extract JSON
            text = response.text.strip()
            if text.startswith("```json"):
                text = text[7:]
            if text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

            questions = json.loads(text)

            logger.success(f"âœ“ Generated {len(questions)} questions for {sutra_id}")
            return questions

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON for {sutra_id}: {e}")
            logger.error(f"Raw response: {text[:500]}")
            return []
        except Exception as e:
            logger.error(f"Error generating questions for {sutra_id}: {e}")
            return []

    def build_golden_set(
        self,
        target_count: int = 100,
        questions_per_sutra: int = 5,
        rate_limit_delay: float = 1.0
    ):
        """Build golden set by sampling diverse sutras"""

        logger.info(f"Loading source summaries from {self.source_summaries_path}")
        summaries_data = self._load_source_summaries()
        summaries = summaries_data['summaries']

        # Current count
        current_count = len(self.golden_set['questions'])
        logger.info(f"Current golden set size: {current_count}")

        if current_count >= target_count:
            logger.info(f"Golden set already has {current_count} questions (target: {target_count})")
            return

        needed = target_count - current_count
        num_sutras_needed = (needed + questions_per_sutra - 1) // questions_per_sutra

        logger.info(f"Need {needed} more questions")
        logger.info(f"Will process ~{num_sutras_needed} sutras ({questions_per_sutra} Q/sutra)")

        # Sample diverse sutras across traditions and periods
        sutra_list = list(summaries.items())

        # Track progress
        processed = 0
        total_questions_added = 0

        for sutra_id, summary_data in sutra_list:
            if total_questions_added >= needed:
                break

            # Skip if already have questions from this sutra
            existing_ids = {q['sutra_id'] for q in self.golden_set['questions']}
            if sutra_id in existing_ids:
                continue

            logger.info(f"[{processed+1}/{num_sutras_needed}] Processing {sutra_id}: {summary_data.get('title_ko', 'Unknown')[:50]}...")

            questions = self.generate_questions_for_sutra(
                sutra_id=sutra_id,
                title_ko=summary_data.get('title_ko', 'Unknown'),
                brief_summary=summary_data.get('brief_summary', ''),
                detailed_summary=summary_data.get('detailed_summary', ''),
                key_themes=summary_data.get('key_themes', []),
                tradition=summary_data.get('tradition', 'Unknown'),
                num_questions=questions_per_sutra
            )

            if questions:
                self.golden_set['questions'].extend(questions)
                total_questions_added += len(questions)
                processed += 1

                # Save checkpoint
                self.golden_set['metadata']['total_questions'] = len(self.golden_set['questions'])
                self.golden_set['metadata']['updated_at'] = time.strftime('%Y-%m-%d %H:%M:%S')

                with open(self.output_path, 'w', encoding='utf-8') as f:
                    json.dump(self.golden_set, f, ensure_ascii=False, indent=2)

                logger.info(f"  Added {len(questions)} questions. Total: {len(self.golden_set['questions'])}/{target_count}")

            # Rate limiting
            time.sleep(rate_limit_delay)

        logger.success(f"\nâœ“ Golden set construction complete!")
        logger.info(f"  Total questions: {len(self.golden_set['questions'])}")
        logger.info(f"  Unique sutras: {len(set(q['sutra_id'] for q in self.golden_set['questions']))}")
        logger.info(f"  Output: {self.output_path}")

        # Category distribution
        categories = {}
        for q in self.golden_set['questions']:
            cat = q.get('category', 'unknown')
            categories[cat] = categories.get(cat, 0) + 1

        logger.info(f"\n  Category distribution:")
        for cat, count in categories.items():
            logger.info(f"    {cat}: {count}")


if __name__ == "__main__":
    # Paths
    SUMMARIES_PATH = "../source_explorer/source_data/source_summaries_ko.json"
    OUTPUT_PATH = "golden_set.json"

    # Configuration
    TARGET_COUNT = 100  # Target number of Q&A pairs
    QUESTIONS_PER_SUTRA = 5  # Questions to generate per sutra
    RATE_LIMIT_DELAY = 1.5  # Seconds between API calls

    # Change to script directory
    script_dir = Path(__file__).parent
    os.chdir(script_dir)

    logger.info("ðŸ”¨ Golden Set Builder for Buddhist RAG Evaluation")
    logger.info(f"Target: {TARGET_COUNT} Q&A pairs")
    logger.info(f"Using: {MODEL_NAME}")
    logger.info("Press Ctrl+C to stop (progress will be saved)\n")

    try:
        builder = GoldenSetBuilder(
            source_summaries_path=SUMMARIES_PATH,
            output_path=OUTPUT_PATH
        )

        builder.build_golden_set(
            target_count=TARGET_COUNT,
            questions_per_sutra=QUESTIONS_PER_SUTRA,
            rate_limit_delay=RATE_LIMIT_DELAY
        )

    except KeyboardInterrupt:
        logger.warning("\nInterrupted by user. Progress has been saved.")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        sys.exit(1)
