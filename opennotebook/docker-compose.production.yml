version: '3.8'

# ==========================================
# Buddha Korea RAG Chatbot - GCP Production
# ==========================================
# Simplified version using file-based ChromaDB

services:
  # Redis for Analytics
  redis:
    image: redis:7-alpine
    container_name: buddhakorea-redis
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - ./redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./redis-data:/data
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD:-changeme}
    ports:
      - "6379:6379"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-changeme}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - buddhist-ai-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # FastAPI Backend with file-based ChromaDB
  fastapi:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: buddhakorea-fastapi
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./chroma_db:/app/chroma_db  # Mount ChromaDB (needs write for sqlite WAL)
      - ./logs:/app/logs
      - ./source_explorer:/app/source_explorer
    environment:
      # API Keys from .env file
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}

      # Model Configuration
      - LLM_MODEL=${LLM_MODEL:-gemini-2.5-pro}

      # GCP Gemini for embeddings (production)
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - GCP_LOCATION=${GCP_LOCATION:-us-central1}
      - USE_GEMINI_FOR_QUERIES=${USE_GEMINI_FOR_QUERIES:-true}

      # ChromaDB file-based path
      - CHROMA_DB_PATH=./chroma_db
      - CHROMA_COLLECTION_NAME=${CHROMA_COLLECTION_NAME:-cbeta_sutras_gemini}

      # Redis Analytics
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-changeme}
      - REDIS_DB=0

      # API Settings
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS}
      - RATE_LIMIT_PER_HOUR=${RATE_LIMIT_PER_HOUR:-100}
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # Retrieval Settings
      - TOP_K_RETRIEVAL=${TOP_K_RETRIEVAL:-10}
      - USE_HYDE=${USE_HYDE:-false}
    env_file:
      - .env
    ports:
      - "8000:8000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - buddhist-ai-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: buddhakorea-nginx
    depends_on:
      fastapi:
        condition: service_healthy
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./static:/var/www/static:ro
      - /var/www/certbot:/var/www/certbot:ro
    ports:
      - "80:80"
      - "443:443"
    restart: unless-stopped
    networks:
      - buddhist-ai-network

networks:
  buddhist-ai-network:
    driver: bridge
